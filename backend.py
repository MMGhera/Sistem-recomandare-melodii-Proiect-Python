#V4V4
import sys
import os
import json
import torch
import numpy as np
import librosa
import ai.dataset
# √éi spunem lui Python: "C√¢nd cineva cautƒÉ 'dataset', dƒÉ-i 'ai.dataset'"
sys.modules['dataset'] = ai.dataset

import requests
import uuid # Pentru nume unice la fi»ôiere temporare
from fastapi import FastAPI, HTTPException, Depends
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from contextlib import asynccontextmanager
from typing import List
from sqlalchemy.orm import Session

# --- IMPORTURI DB ---
from models import create_tables, get_db, User, Song, UserPreference, SessionLocal

# --- SETUP IMPORTURI AI ---
sys.path.append(os.path.dirname(__file__))
try:
    from ai.model import MusiCNN, INSTRUMENT_MAP
    from ai.dataset import generate_melspectrogram
except ImportError:
    pass  # IgnorƒÉm dacƒÉ nu merge importul local, doar pentru test

# --- CONFIGURARE AI ---
AI_MODEL_PATH = os.path.join("ai", "checkpoints", "big_sample_rate", "best.pt")
AUDIO_LIBRARY_PATH = "audio_library"
ai_context = {"model": None, "config": None, "device": None}


# --- LIFESPAN ---
@asynccontextmanager
async def lifespan(app: FastAPI):
    # 1. Ini»õializƒÉm Baza de Date SQL
    create_tables()
    print("üíæ Baza de date SQL conectatƒÉ.")

    # 2. √éncƒÉrcƒÉm AI-ul
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    if os.path.exists(AI_MODEL_PATH):
        try:
            state = torch.load(AI_MODEL_PATH, map_location=device, weights_only=False)
            mel_conf = state["mel_config"]
            instrument_list = state["instrument_list"]
            model = MusiCNN(num_classes=len(instrument_list), num_mels=mel_conf.n_mels)
            model.load_state_dict(state["model"])
            model.to(device)
            model.eval()

            ai_context.update({"model": model, "device": device, "config": {
                "mel_config": mel_conf, "frames_per_window": state["frames_per_window"]
            }})
            print("‚úÖ Model AI √ÆncƒÉrcat.")
        except Exception as e:
            print(f"‚ùå Eroare AI: {e}")

    yield


app = FastAPI(lifespan=lifespan)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"], allow_credentials=True, allow_methods=["*"], allow_headers=["*"],
)


# --- LOGICA AI (Aceea»ôi ca √Ænainte) ---

def analyze_audio_file(file_path):
    # VerificƒÉri preliminare
    model = ai_context["model"]
    cfg = ai_context["config"]
    device = ai_context["device"]

    if model is None:
        return None

    try:
        # 1. √éncƒÉrcare Audio (cu librosa)
        # Folosind try-catch intern pentru a prinde erorile specifice de codec
        audio, sr = librosa.load(file_path, sr=None)

        # 2. Resample la frecven»õa modelului
        audio = librosa.resample(audio, orig_sr=sr, target_sr=cfg["mel_config"].sample_rate)

        # 3. Generare SpectrogramƒÉ
        mel = generate_melspectrogram(audio, cfg["mel_config"])

        # 4. √émpƒÉr»õire √Æn bucƒÉ»õi (Chunking)
        frames_win = cfg["frames_per_window"]
        chunks = []
        total_frames = mel.shape[1]

        for offset in range(0, total_frames, frames_win):
            chunk = mel[:, offset:offset + frames_win]
            if chunk.shape[1] < frames_win:
                pad_width = frames_win - chunk.shape[1]
                chunk = np.pad(chunk, ((0, 0), (0, pad_width)), mode='constant')
            chunks.append(chunk)

        if not chunks:
            return None

        # 5. Predic»õie AI
        batch_tensor = np.stack(chunks)
        batch_tensor = torch.from_numpy(batch_tensor).float().unsqueeze(1).to(device)

        with torch.no_grad():
            logits = model(batch_tensor)
            probs = logits.cpu().numpy()

        # 6. Agregare rezultate (Max Pooling)
        song_vector = np.max(probs, axis=0)
        return song_vector.tolist()

    except Exception as e:
        # DacƒÉ apare o eroare, o afi»ôƒÉm discret √Æn consolƒÉ »ôi returnƒÉm None
        # astfel √Ænc√¢t scanarea sƒÉ continue cu urmƒÉtoarea melodie
        print(f"‚ö†Ô∏è Nu s-a putut analiza {os.path.basename(file_path)}: {e}")
        return None


# --- MODELE PYDANTIC (Pentru API) ---
class LoginRequest(BaseModel):
    username: str


class PrefsRequest(BaseModel):
    username: str
    songs: list[str]


# --- ENDPOINTS NOI CU SQL ---

@app.post("/login")
def login(request: LoginRequest, db: Session = Depends(get_db)):
    # CƒÉutƒÉm userul √Æn SQL
    user = db.query(User).filter(User.username == request.username).first()
    if not user:
        # CreƒÉm user nou
        new_user = User(username=request.username)
        db.add(new_user)
        db.commit()
    return {"status": "ok", "username": request.username}


@app.get("/prefs/{username}")
def get_prefs(username: str, db: Session = Depends(get_db)):
    user = db.query(User).filter(User.username == username).first()
    if not user:
        return {"songs": []}

    # Extragem numele melodiilor din tabelul de preferin»õe
    song_titles = [pref.song.title for pref in user.preferences]
    return {"songs": song_titles}


@app.post("/prefs")
def save_prefs(request: PrefsRequest, db: Session = Depends(get_db)):
    user = db.query(User).filter(User.username == request.username).first()
    if not user:
        raise HTTPException(status_code=404, detail="User not found")

    # »òtergem preferin»õele vechi (cea mai simplƒÉ metodƒÉ de update)
    db.query(UserPreference).filter(UserPreference.user_id == user.id).delete()

    # AdƒÉugƒÉm noile preferin»õe
    for song_name in request.songs:
        # VerificƒÉm dacƒÉ melodia existƒÉ √Æn baza de date
        song = db.query(Song).filter(Song.title == song_name).first()
        if song:
            new_pref = UserPreference(user_id=user.id, song_id=song.id)
            db.add(new_pref)

    db.commit()
    return {"status": "ok"}


@app.get("/autocomplete")
def autocomplete(q: str, db: Session = Depends(get_db)):
    # CƒÉutare SQL (LIKE %q%)
    songs = db.query(Song).filter(Song.title.contains(q)).limit(10).all()
    return [s.title for s in songs]


@app.post("/scan_library")
def scan_library(db: Session = Depends(get_db)):
    # ImportƒÉm logica de analizƒÉ din contextul global sau func»õia definitƒÉ
    # Nota: Trebuie sƒÉ incluzi func»õia analyze_audio_file completƒÉ √Æn acest fi»ôier
    from ai.dataset import generate_melspectrogram  # Re-import pt siguran»õƒÉ

    if not os.path.exists(AUDIO_LIBRARY_PATH):
        return {"error": "No audio folder"}

    processed = 0
    files = os.listdir(AUDIO_LIBRARY_PATH)

    for file in files:
        if file.endswith((".mp3", ".wav", ".m4a")):
            song_name = os.path.splitext(file)[0]

            # VerificƒÉm dacƒÉ existƒÉ deja √Æn SQL
            exists = db.query(Song).filter(Song.title == song_name).first()
            if not exists:
                print(f"üéµ Analizez: {song_name}...")
                full_path = os.path.join(AUDIO_LIBRARY_PATH, file)

                # AICI apelƒÉm AI-ul tƒÉu
                # vector = analyze_audio_file(full_path)
                # (Simulare vector pentru exemplul DB - tu decomenteazƒÉ analiza realƒÉ)
                #vector = [0.1, 0.2, 0.3]  # Placeholder dacƒÉ nu merge analiza pe moment
                try:
                    vector = analyze_audio_file(full_path)
                except Exception as e:
                    print(f"Eroare la analiza {song_name}: {e}")
                    vector = None

                if vector:
                    new_song = Song(
                        title=song_name,
                        vector_data=json.dumps(vector)  # SalvƒÉm vectorul ca text JSON
                    )
                    db.add(new_song)
                    processed += 1
                    db.commit()  # SalvƒÉm fiecare melodie pe r√¢nd

    return {"status": "completed", "new_songs": processed}


@app.get("/recommend/{username}")
def recommend(username: str, db: Session = Depends(get_db)):
    user = db.query(User).filter(User.username == username).first()
    if not user or not user.preferences:
        return {"recommendations": ["AdaugƒÉ preferin»õe!"]}

    # 1. Construim profilul userului
    user_vectors = []
    for pref in user.preferences:
        user_vectors.append(json.loads(pref.song.vector_data))

    if not user_vectors:
        return {"recommendations": []}

    # Media vectorilor
    user_profile = np.mean(np.array(user_vectors), axis=0)

    # 2. LuƒÉm toate melodiile din DB
    all_songs = db.query(Song).all()
    scores = []

    my_song_ids = [p.song_id for p in user.preferences]

    for song in all_songs:
        if song.id in my_song_ids: continue  # Excludem ce ascultƒÉ deja

        song_vec = np.array(json.loads(song.vector_data))

        # Cosine Similarity
        similarity = np.dot(user_profile, song_vec) / (np.linalg.norm(user_profile) * np.linalg.norm(song_vec))

        if similarity > 0.35:  # Prag minim
            scores.append((song.title, similarity))

    scores.sort(key=lambda x: x[1], reverse=True)
    return {"recommendations": [s[0] for s in scores[:5]]}


# --- ENDPOINT NOU: ANALIZƒÇ EXTERNƒÇ LIVE ---
@app.get("/analyze_external")
def analyze_external(q: str, username: str, db: Session = Depends(get_db)):
    """
    CautƒÉ pe iTunes, analizeazƒÉ, SALVEAZƒÇ √Æn DB »ôi adaugƒÉ la PREFERIN»öELE utilizatorului.
    """
    print(f"üåç {username} cautƒÉ »ôi adaugƒÉ: {q}")

    # 1. CƒÉutare pe iTunes
    itunes_url = f"https://itunes.apple.com/search?term={q}&media=music&entity=song&limit=1"
    try:
        resp = requests.get(itunes_url).json()
        if not resp["results"]:
            return {"error": "Melodia nu a fost gƒÉsitƒÉ pe iTunes."}

        track = resp["results"][0]
        full_name = f"{track['artistName']} - {track['trackName']}"
        preview_url = track["previewUrl"]

        # 2. Gestionare Melodie √Æn DB (VerificƒÉm / AdƒÉugƒÉm)
        song_in_db = db.query(Song).filter(Song.title == full_name).first()

        target_vector = None

        if song_in_db:
            print("‚ö° Melodia existƒÉ deja. O refolosim.")
            target_vector = json.loads(song_in_db.vector_data)
        else:
            # Nu existƒÉ -> O descƒÉrcƒÉm »ôi analizƒÉm
            print("‚¨áÔ∏è Descarc »ôi analizez melodia nouƒÉ...")
            temp_path = os.path.join(AUDIO_LIBRARY_PATH, f"temp_{uuid.uuid4()}.m4a")
            os.makedirs(AUDIO_LIBRARY_PATH, exist_ok=True)

            r = requests.get(preview_url)
            with open(temp_path, 'wb') as f:
                f.write(r.content)

            target_vector = analyze_audio_file(temp_path)

            if os.path.exists(temp_path):
                os.remove(temp_path)  # »òtergem fi»ôierul audio, pƒÉstrƒÉm doar matematica

            if target_vector:
                # SALVARE PERMANENTƒÇ √éN BAZA DE DATE
                song_in_db = Song(title=full_name, vector_data=json.dumps(target_vector))
                db.add(song_in_db)
                db.commit()
                db.refresh(song_in_db)
            else:
                return {"error": "AI-ul nu a putut analiza fi»ôierul."}

        # 3. AdƒÉugare la Preferin»õele Utilizatorului (Link User <-> Song)
        user = db.query(User).filter(User.username == username).first()
        if user:
            # VerificƒÉm dacƒÉ nu o are deja
            existing_pref = db.query(UserPreference).filter(
                UserPreference.user_id == user.id,
                UserPreference.song_id == song_in_db.id
            ).first()

            if not existing_pref:
                new_pref = UserPreference(user_id=user.id, song_id=song_in_db.id)
                db.add(new_pref)
                db.commit()
                print(f"‚úÖ AdƒÉugat '{full_name}' la preferin»õele lui {username}.")

    except Exception as e:
        return {"error": f"Eroare server: {str(e)}"}

    # 4. RecomandƒÉri (Bazat pe melodia tocmai adƒÉugatƒÉ)
    all_songs = db.query(Song).all()
    scores = []
    target_np = np.array(target_vector)

    for song in all_songs:
        if song.id == song_in_db.id: continue  # Nu ne recomandƒÉm pe noi √Æn»ôine

        song_vec = np.array(json.loads(song.vector_data))
        similarity = np.dot(target_np, song_vec) / (np.linalg.norm(target_np) * np.linalg.norm(song_vec))
        scores.append((song.title, similarity))

    scores.sort(key=lambda x: x[1], reverse=True)

    return {
        "source_song": full_name,
        "recommendations": [s[0] for s in scores[:5]],
        "added_to_library": True
    }


@app.get("/itunes_autocomplete")
def itunes_autocomplete(q: str):
    """
    ReturneazƒÉ o listƒÉ scurtƒÉ de sugestii de la iTunes (Titlu + Artist).
    """
    if not q or len(q) < 2:
        return []

    # Cerem doar 5 rezultate pentru vitezƒÉ
    url = f"https://itunes.apple.com/search?term={q}&media=music&entity=song&limit=5"
    try:
        resp = requests.get(url).json()
        results = []
        for track in resp.get("results", []):
            # FormatƒÉm frumos: "Artist - PiesƒÉ"
            display_name = f"{track['artistName']} - {track['trackName']}"
            results.append(display_name)
        # EliminƒÉm duplicatele (set) »ôi returnƒÉm lista
        return list(set(results))
    except:
        return []


# --- ENDPOINT »òTERGERE PREFERIN»öƒÇ ---
@app.delete("/pref")
def delete_pref(username: str, song: str, db: Session = Depends(get_db)):
    user = db.query(User).filter(User.username == username).first()
    if not user:
        return {"error": "User not found"}

    # GƒÉsim melodia
    song_obj = db.query(Song).filter(Song.title == song).first()
    if song_obj:
        # »òtergem legƒÉtura dintre user »ôi melodie
        db.query(UserPreference).filter(
            UserPreference.user_id == user.id,
            UserPreference.song_id == song_obj.id
        ).delete()
        db.commit()
        print(f"üóëÔ∏è {username} a »ôters: {song}")
        return {"status": "deleted"}

    return {"status": "song not found (ignored)"}

if __name__ == "__main__":
    import uvicorn
    # Asta »õine programul deschis »ôi ascultƒÉ cereri
    uvicorn.run(app, host="127.0.0.1", port=8000)